{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from astra.torch.al.strategies.base import Strategy\n",
    "from astra.torch.al.acquisitions.base import DeterministicAcquisition\n",
    "from astra.torch.al.errors import AcquisitionMismatchError\n",
    "\n",
    "from typing import Sequence, Dict, Union\n",
    "\n",
    "\n",
    "class DeterministicStrategy(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        acquisitions: Union[DeterministicAcquisition, Sequence[DeterministicAcquisition]],\n",
    "        inputs: torch.Tensor,\n",
    "        outputs: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"Base class for query strategies\n",
    "\n",
    "        Args:\n",
    "            acquisitions: A sequence of acquisition functions.\n",
    "            inputs: A tensor of inputs.\n",
    "            outputs: A tensor of outputs.\n",
    "        \"\"\"\n",
    "        super().__init__(acquisitions, inputs, outputs)\n",
    "\n",
    "        for name, acquisition in self.acquisitions.items():\n",
    "            if not isinstance(acquisition, DeterministicAcquisition):\n",
    "                raise AcquisitionMismatchError(DeterministicAcquisition, acquisition)\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        net: nn.Module,\n",
    "        pool_indices: torch.Tensor,\n",
    "        context_indices: torch.Tensor = None,\n",
    "        n_query_samples: int = 1,\n",
    "        n_mc_samples: int = 10,\n",
    "        batch_size: int = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Monte Carlo query strategy\n",
    "\n",
    "        Args:\n",
    "            net: A neural network with dropout layers.\n",
    "            pool_indices: The indices of the pool set.\n",
    "            context_indices: This argument is ignored.\n",
    "            n_query_samples: Number of samples to query.\n",
    "            n_mc_samples: This argument is ignored.\n",
    "            batch_size: Batch size for the data loader.\n",
    "\n",
    "        Returns:\n",
    "            best_indices: A dictionary of acquisition names and the corresponding best indices.\n",
    "        \"\"\"\n",
    "        assert isinstance(pool_indices, torch.Tensor), f\"pool_indices must be a torch.Tensor, got {type(pool_indices)}\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = len(pool_indices)\n",
    "\n",
    "        data_loader = DataLoader(self.dataset[pool_indices])\n",
    "\n",
    "        # put the model on eval mode\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_list = []\n",
    "            for x, _ in data_loader:\n",
    "                logits = net(x)\n",
    "                logits_list.append(logits)\n",
    "            logits = torch.cat(logits_list, dim=1)  # (pool_dim, n_classes)\n",
    "\n",
    "            best_indices = {}\n",
    "            for acq_name, acquisition in self.acquisitions.items():\n",
    "                scores = acquisition.acquire_scores(logits)\n",
    "                index = torch.topk(scores, n_query_samples).indices\n",
    "                selected_indices = pool_indices[index]\n",
    "                best_indices[acq_name] = selected_indices\n",
    "\n",
    "        return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astra.torch.al.acquisitions.entropy import EntropyAcquisition\n",
    "import pytest\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from astra.torch.models import CNN\n",
    "# from astra.torch.al import UniformRandomAcquisition, RandomStrategy, EnsembleAcquisition\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_entropy():\n",
    "    data = CIFAR10(root=\"data\", download=True, train=False)  # \"test\" for less data\n",
    "    inputs = torch.tensor(data.data).float().to(device)\n",
    "    outputs = torch.tensor(data.targets).long().to(device)\n",
    "    \n",
    "    #Meta parameters\n",
    "    n_pool = 1000\n",
    "    indices = torch.randperm(len(inputs))\n",
    "    pool_indices = indices[:n_pool]\n",
    "    train_indices = indices[n_pool:]\n",
    "    n_query_samples = 10\n",
    "\n",
    "        # Define the acquisition function\n",
    "    acquisition = EntropyAcquisition()\n",
    "    strategy = DeterministicStrategy(acquisition, inputs, outputs)\n",
    "    strategy.to(device)\n",
    "    net = CNN(32, 3, 3, [4, 8], [2, 3], 10).to(device)\n",
    "    best_indices = strategy.query(net, pool_indices, n_query_samples=n_query_samples)\n",
    "    print(best_indices)\n",
    "    assert best_indices['EntropyAcquisition'].shape==(n_query_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [08:14<00:00, 344553.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_entropy()\n",
      "\u001b[1;32m/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m strategy\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m net \u001b[39m=\u001b[39m CNN(\u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, [\u001b[39m4\u001b[39m, \u001b[39m8\u001b[39m], [\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m], \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m best_indices \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mquery(net, pool_indices, n_query_samples\u001b[39m=\u001b[39;49mn_query_samples)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(best_indices)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39massert\u001b[39;00m best_indices[\u001b[39m'\u001b[39m\u001b[39mEntropyAcquisition\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m==\u001b[39m(n_query_samples,)\n",
      "\u001b[1;32m/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     logits_list \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x, _ \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m         logits \u001b[39m=\u001b[39m net(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/ASTRA-2/tests/torch/acquisitions/test_entropy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m         logits_list\u001b[39m.\u001b[39mappend(logits)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "test_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
